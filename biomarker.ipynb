{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T08:19:07.204036Z",
     "start_time": "2019-10-21T08:19:02.497197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\nimport warnings\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\n\\n#%matplotlib inline;\\nimport ast\\nimport json\\nfrom pandas.io.json import json_normalize\\n\\nimport datetime\\nimport time\\nimport math\\n\\nfrom scipy import stats\\nfrom scipy import signal as spsg\\n\\nMETADATA = \\\"../../metadata/\\\"\\nSENSORDATA = \\\"../../sensordata/\\\"\\n\\nwarnings.simplefilter(action=\\\"ignore\\\", category=FutureWarning)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#%matplotlib inline;\n",
    "import ast\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "from scipy import stats\n",
    "from scipy import signal as spsg\n",
    "\n",
    "METADATA = \"../../metadata/\"\n",
    "SENSORDATA = \"../../sensordata/\"\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "def get_derivative(df, timedelta, d=1):\n",
    "\n",
    "    \"\"\"sensordata로 구성된 pandas series or dataframe과 timedelta(측정 시간 간격)을 받아 미분 값을 반환한다. \n",
    "\n",
    "        Args:\n",
    "            df: sensordata (timeseries) df or series\n",
    "            timedelta: dt\n",
    "            d: df dimension\n",
    "            \n",
    "        Returns:\n",
    "            dataframe or series of derivative of df\n",
    "        \"\"\"\n",
    "\n",
    "    if d == 2:\n",
    "            return pd.DataFrame(\n",
    "                np.gradient(df, timedelta, axis=0),\n",
    "                columns=[\"Palm\", \"Index\", \"Middle\", \"Ring\", \"Pinky\"],\n",
    "            )\n",
    "        else:\n",
    "            return pd.Series(np.gradient(df, timedelta, axis=0).flatten())\n",
    "\n",
    "def butterworth_filter(order, cutoff, timedelta):\n",
    "\n",
    "    \"\"\"Butterworth lowpass filter for high frequency noise & outliers (mostly sensor error)\n",
    "    \n",
    "        Args:\n",
    "            order: order of filter\n",
    "            cutoff: threshold frequency\n",
    "            timedelta: dt\n",
    "            \n",
    "        Returns:\n",
    "            dataframe or series of derivative of df\n",
    "    \"\"\"\n",
    "\n",
    "    sampling_rate = 1 / timedelta\n",
    "    wn = cutoff / (sampling_rate * 0.5)\n",
    "    # Nyquist frequency = 0.5 * sampling rate\n",
    "    b, a = spsg.butter(order, wn, btype=\"lowpass\")\n",
    "    print(\"Butterworth Filter: Order n = \", order, \"Cutoff \", cutoff, \"Hz\")\n",
    "\n",
    "    return b, a\n",
    "\n",
    "def reject_outliers(data, types):\n",
    "\n",
    "    \"\"\"시스템 상에서 센서데이터 처리 방식 오류로 인한 에러 처리\n",
    "    속도 기준 720 deg/s, 가속도 기준 21600 deg/s^2 넘을 시 interpolation 값으로 대체\n",
    "    \n",
    "        Args:\n",
    "            data: dataframe OR series of speed OR acc\n",
    "            types: speed OR acceleration\n",
    "            \n",
    "        Returns:\n",
    "            dataframe or series with interpolated values for outliers\n",
    "    \"\"\"\n",
    "\n",
    "    if types == \"speed\":\n",
    "        threshold = 720\n",
    "    elif types == \"acceleration\":\n",
    "        threshold = 21600\n",
    "    data = np.asarray(data)\n",
    "    data = np.where(np.abs(data) < threshold, data, np.nan)\n",
    "    data[np.isnan(data)] = np.interp(\n",
    "        np.isnan(data).nonzero()[0],\n",
    "        np.isfinite(data).nonzero()[0],\n",
    "        data[np.isfinite(data)],\n",
    "    )\n",
    "\n",
    "    return data\n",
    "\n",
    "def zero_crossing(my_array, threshold):\n",
    "\n",
    "    \"\"\"Count zero crossings of value with threshold. \n",
    "    Value should not only change its sign but its change should exceed threshold\n",
    "    \n",
    "        Args:\n",
    "            my_array: dataframe OR series OR numpy array of speed OR acc\n",
    "            threshold: threshold value\n",
    "            \n",
    "        Returns:\n",
    "            Count of zerocrossings over threshold \n",
    "    \"\"\"\n",
    "\n",
    "    my_array = np.asarray(my_array)\n",
    "    return (\n",
    "        ((my_array[:-1] * my_array[1:]) < 0)\n",
    "        & (abs(my_array[:-1] - my_array[1:]) > threshold)\n",
    "    ).sum()\n",
    "\n",
    "def check_treasure_range(window, ranges):\n",
    "\n",
    "    \"\"\"주어진 Pandas Series 또는 DataFrame type의 데이터를 미분(정확히는 gradient)한다. \n",
    "    \n",
    "    Args:\n",
    "        df: 미분하고자 하는 pandas series OR dataframe\n",
    "        timedelta: 미분하고자 하는 데이터셋의 시간간격(단위: 초)\n",
    "        d: 미분해야하는 column이 여러 개일 경우 True (e.g. Finger F/E 컨텐츠는 5개 column이 함께 계산되어야 함)\n",
    "        \n",
    "    Returns:\n",
    "        Input에 따라 미분된 Pandas Series 또는 DataFrame \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    window_ls = [min(window), max(window)]\n",
    "\n",
    "    range_ls = []\n",
    "    for tp in ranges:\n",
    "        range_ls.append(tp[0])\n",
    "        range_ls.append(tp[1])\n",
    "    range_ls\n",
    "\n",
    "    check = np.digitize(window_ls, bins=range_ls)\n",
    "\n",
    "    if check[0] == check[1] and check[0] % 2 == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "class EMR:\n",
    "\n",
    "    \"\"\"훈련결과 인스턴스.\n",
    "    \n",
    "    유저가 수행완료한 훈련컨텐츠에 대한 결과 정보를 담고 있다.\n",
    "    센서데이터 단위에서 도출가능한 정보 및 각종 바이오마커가 본 인스턴스를 통해 계산되고 시각화된다.\n",
    "    \n",
    "    Attributes:\n",
    "        mid: integer. mission id. in Live or Alpha DB.\n",
    "        uid2: string. unique string with length 2 in case of multiple EMR for the same mission id.\n",
    "        pid: integer. patient id.\n",
    "        cid: string. content name. (e.g. 'SMART_GLOVE_FISHING')\n",
    "        tt: string. training type. (e.g. 'SMART_GLOVE_FOREARM_SUP_PRONATION')\n",
    "        range: list. ROM used for the gameplay, calculated by {calibration range} * {arom ratio}\n",
    "        effective_range: list. ROM that are counted as a motion success in the gameplay. depends on contents.\n",
    "        treatment: True/False. True for actual user (patients), False for test user.\n",
    "        patient_info: list. patient's info in order of [{nickname}, {birthday}, {gender}] from Live DB.\n",
    "        time: string. timestamp when emr generated\n",
    "        timedelta: float. average dt of sensordata (seconds)\n",
    "        playtime: int. total played time\n",
    "        num_lackpeak: int. number of peaks user have made but failed to maintain 5 seconds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mission_id, treatment = True):\n",
    "\n",
    "        \"\"\"EMR 생성자.\n",
    "\n",
    "        Args:\n",
    "            mission_id: integer. mission id. in Live or Alpha DB.\n",
    "            treatment: True/False. True for actual user (patients), False for test user.\n",
    "\n",
    "        Raises:\n",
    "            입력한 mission id에 해당하는 훈련결과가 여러 개일 경우, \n",
    "            각 훈련결과 정보(훈련일자 및 시간, 훈련소요시간)를 출력한 후 uid2를 입력받는다.\n",
    "        \"\"\"\n",
    "\n",
    "        content = pd.read_csv(METADATA + \"content_training_type.csv\")\n",
    "        # Class variable: content와 training type matching을 갖고 있는 테이블\n",
    "\n",
    "        self.mid = mission_id\n",
    "        self.treatment = treatment\n",
    "\n",
    "        # if patient,\n",
    "        if treatment == 1:\n",
    "\n",
    "            patient = pd.read_csv(METADATA + \"p1_patient_list.csv\")\n",
    "\n",
    "            match = pd.read_csv(METADATA + \"p1_mission_list.csv\")\n",
    "            match.dropna(subset=[\"uid2\"], inplace=True)\n",
    "            match[\"calibration_range\"] = match[\"calibration_range\"].apply(\n",
    "                ast.literal_eval\n",
    "            )\n",
    "            match.uid2.apply(str)\n",
    "\n",
    "            # mission id가 같은 exercise_mission_result가 여러 개일 경우 별도 unique id를 입력\n",
    "            if len(match.loc[match[\"mission_id\"] == mission_id]) > 1:\n",
    "                print(\n",
    "                    \"There are multiple exercise mission results:\",\n",
    "                    match.loc[match[\"mission_id\"] == mission_id][\n",
    "                        [\n",
    "                            \"exercise_mission_result_generated_time\",\n",
    "                            \"played_time\",\n",
    "                            \"uid2\",\n",
    "                        ]\n",
    "                    ],\n",
    "                )\n",
    "                self.uid2 = str(input(\"Pick one of those and input uid2\"))\n",
    "                idx = match.loc[\n",
    "                    (match[\"mission_id\"] == mission_id) & (match[\"uid2\"] == self.uid2)\n",
    "                ].index.item()\n",
    "            else:\n",
    "                idx = match.loc[match[\"mission_id\"] == mission_id].index.item()\n",
    "                self.uid2 = match.loc[idx, \"uid2\"]\n",
    "\n",
    "            self.pid = match.loc[idx, \"patient_id\"]\n",
    "            self.patient_info = patient.loc[\n",
    "                patient[\"patient_id\"] == self.pid,\n",
    "                [\"patient_nickname\", \"patient_birthday\", \"patient_gender\"],\n",
    "            ].values\n",
    "\n",
    "        # if general,\n",
    "        elif treatment == 0:\n",
    "\n",
    "            self.patient_info = \"Control group\"\n",
    "\n",
    "            match = pd.read_csv(METADATA + \"g1_mission_list.csv\")\n",
    "            match[\"calibration_range\"] = match[\"calibration_range\"].apply(\n",
    "                ast.literal_eval\n",
    "            )\n",
    "\n",
    "            if len(match.loc[match[\"mission_id\"] == mission_id]) > 1:\n",
    "                idx = match.loc[\n",
    "                    match[\"mission_id\"] == mission_id, \"played_time\"\n",
    "                ].idxmax()\n",
    "            else:\n",
    "                idx = match.loc[match[\"mission_id\"] == mission_id].index.item()\n",
    "\n",
    "            self.pid = 0\n",
    "            self.uid2 = \"00\"\n",
    "\n",
    "        self.time = match.loc[idx, \"exercise_mission_result_generated_time\"]\n",
    "        self.cid = match.loc[idx, \"content_id\"]\n",
    "        self.tt = content.loc[\n",
    "            content[\"content_id\"] == match.loc[idx, \"content_id\"], \"training_type_name\"\n",
    "        ].item()\n",
    "        self.playtime = match.loc[idx, \"played_time\"]\n",
    "        self.arom_ratio = match.loc[idx, \"arom_ratio\"]\n",
    "\n",
    "        # Get calibration range (게임컨텐츠 내에서 성공 여부를 판단하는 ROM 계산)\n",
    "        ls = list(match.loc[idx, \"calibration_range\"].values())\n",
    "        if len(ls) == 1:\n",
    "            calrange = abs(ls[0][1] - ls[0][0])\n",
    "            rangemax = max(ls[0][1], ls[0][0]) - (\n",
    "                (calrange * (1 - self.arom_ratio)) / 2\n",
    "            )\n",
    "            rangemin = min(ls[0][1], ls[0][0]) + (\n",
    "                (calrange * (1 - self.arom_ratio)) / 2\n",
    "            )\n",
    "            self.range = [rangemin, rangemax]\n",
    "        else:\n",
    "            self.range = ls\n",
    "\n",
    "    def effective_range(self):\n",
    "\n",
    "        \"\"\"실제 훈련에서 유효한 ROM 범위를 계산한다.\n",
    "        \n",
    "        훈련종류에 따라 동작성공에 해당하는 ROM 범위가 다르기 때문에 \n",
    "        calibration을 통해 수집된 ROM을 훈련종류에 맞는 수식을 통해 유효 ROM 범위를 계산한다.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        game_rom_minmax = ['SMART_GLOVE_POUR_WINE', 'SMART_GLOVE_FISHING']\n",
    "        game_coordination_div8 = ['SMART_GLOVE_FIND_TREASURE']\n",
    "        game_rom_finger = ['SMART_GLOVE_MAKE_JUICE']\n",
    "        #add game lists and games by appropriate categorization\n",
    "        \n",
    "        if self.cid in game_rom_minmax:\n",
    "            return self.range\n",
    "        elif self.cid in game_coordination_div8:\n",
    "            ls = [(-40) + 80 * i / 7 for i in range(8)]\n",
    "            ls_final = [\n",
    "                (\n",
    "                    (\n",
    "                        (self.range[1] - self.range[0])\n",
    "                        * (j - 360 * np.arcsin(50 / 1053) / np.pi)\n",
    "                        / 80\n",
    "                    )\n",
    "                    + (self.range[1] + self.range[0]) / 2,\n",
    "                    (\n",
    "                        (self.range[1] - self.range[0])\n",
    "                        * (j + 360 * np.arcsin(50 / 1053) / np.pi)\n",
    "                        / 80\n",
    "                    )\n",
    "                    + (self.range[1] + self.range[0]) / 2,\n",
    "                )\n",
    "                for j in ls\n",
    "            ]\n",
    "            return ls_final\n",
    "        elif self.cid in game_rom_finger:\n",
    "            return self.range\n",
    "        else:\n",
    "            return self.range\n",
    "\n",
    "    def show_info(self):\n",
    "\n",
    "        \"\"\"해당 exercise mission result에 대한 기본 정보를 출력한다.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Info of Mission ID #\", self.mid)\n",
    "        print(\"Exercise Mission Result Unique id:\", self.uid2)\n",
    "        print(\"Patient id:\", self.pid)\n",
    "        print(\"Patient info:\", self.patient_info)\n",
    "        print(\"Content name:\", self.cid)\n",
    "        print(\"Exercise time:\", self.time)\n",
    "        print(\"Training type:\", self.tt)\n",
    "        print(\"Calibration range:\", self.range)\n",
    "\n",
    "    def get_df(self, sub = False):\n",
    "\n",
    "        \"\"\"주어진 Pandas Series 또는 DataFrame type의 데이터를 미분(정확히는 gradient)한다. \n",
    "\n",
    "        Args:\n",
    "            sub: T/F. 훈련에 쓰이는 센서데이터 외 센서데이터 사용 여부 (e.g. POUR_WINE 에서 trans Forearm S/P 값 외의 센서값 사용 시 True 입력)\n",
    "            \n",
    "        Returns:\n",
    "            Pandas Series/DataFrame. 해당 EMR에 맞는 sensordataset (if sub == False).\n",
    "            (if sub == True, 입력값에 따른 sensordataset 반환)\n",
    "            \n",
    "        Raises:\n",
    "            if sub == True, 해당 EMR에 맞는 sensordata 외로 어떤 sensordata를 받을 것인지 입력한다. \n",
    "        \"\"\"\n",
    "\n",
    "        if self.treatment == 1:\n",
    "\n",
    "            df = pd.read_csv(\n",
    "                SENSORDATA + \"p1/p1_\" + str(self.mid) + \"_\" + self.uid2 + \".csv\",\n",
    "                thousands=\",\",\n",
    "            )\n",
    "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "            df.sort_values(by=[\"timestamp\"], inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        elif self.treatment == 0:\n",
    "\n",
    "            df = pd.read_csv(\n",
    "                SENSORDATA + \"g1/g1_\" + str(self.mid) + \".csv\", thousands=\",\"\n",
    "            )\n",
    "            df.rename(columns=lambda x: x.replace(\"actionData.\", \"\"), inplace=True)\n",
    "            df[\"timestamp\"] = df[\"@timestamp\"].apply(\n",
    "                lambda x: datetime.datetime.strptime(x, \"%b %d, %Y @ %H:%M:%S.%f\")\n",
    "            )\n",
    "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "            df.sort_values(by=[\"timestamp\"], inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        self.timedelta = 0.001 * np.mean(\n",
    "            np.gradient(df[\"timestamp\"]).astype(\"timedelta64[ms]\").astype(\"float\")\n",
    "        )\n",
    "\n",
    "        if any(\n",
    "            np.gradient(df[\"timestamp\"]).astype(\"timedelta64[ms]\").astype(\"float\")\n",
    "            > 3000\n",
    "        ) or ((self.playtime * 30) > len(df)):\n",
    "            raise ValueError(\n",
    "                \"Possibility of missing data in EMR of \",\n",
    "                self.mid,\n",
    "                \" by \\n\",\n",
    "                \"1) gap of \",\n",
    "                0.001\n",
    "                * max(\n",
    "                    np.gradient(df[\"timestamp\"])\n",
    "                    .astype(\"timedelta64[ms]\")\n",
    "                    .astype(\"float\")\n",
    "                ),\n",
    "                \" seconds, \\n\",\n",
    "                \"2) total about \",\n",
    "                ((self.playtime * 30) - len(df)) / 33,\n",
    "                \" seconds\",\n",
    "            )\n",
    "\n",
    "        if sub == 0:\n",
    "            cal_avg = 0\n",
    "            if self.tt == \"SMART_GLOVE_FOREARM_SUP_PRONATION\":\n",
    "                i = 0\n",
    "                self.trans = 1\n",
    "            elif self.tt == \"SMART_GLOVE_WRIST_FLEX_EXT_AG\":\n",
    "                i = 1\n",
    "                self.trans = 1\n",
    "            elif self.tt == \"SMART_GLOVE_WRIST_DEVIATION_EG\":\n",
    "                i = 2\n",
    "                self.trans = 1\n",
    "            elif self.tt == \"SMART_GLOVE_FINGER_FLEX_EXT\":\n",
    "                i = 3\n",
    "                self.trans = 0\n",
    "            else:\n",
    "                \"Contents that has not yet developed for biomarker search!\"\n",
    "\n",
    "            if self.trans == 1:\n",
    "                ls = [\n",
    "                    \"wristPStrans\",\n",
    "                    \"wristFEtrans\",\n",
    "                    \"wristUDRDtrans\",\n",
    "                    [\n",
    "                        \"fingerPalmtrans\",\n",
    "                        \"fingerIndextrans\",\n",
    "                        \"fingerMiddletrans\",\n",
    "                        \"fingerRingtrans\",\n",
    "                        \"fingerPinkytrans\",\n",
    "                    ],\n",
    "                ]\n",
    "            else:\n",
    "                ls = [\n",
    "                    \"wristPS\",\n",
    "                    \"wristFE\",\n",
    "                    \"wristUDRD\",\n",
    "                    [\n",
    "                        \"fingerPalm\",\n",
    "                        \"fingerIndex\",\n",
    "                        \"fingerMiddle\",\n",
    "                        \"fingerRing\",\n",
    "                        \"fingerPinky\",\n",
    "                    ],\n",
    "                ]\n",
    "\n",
    "            if i == 3:\n",
    "                ls = ls[i]\n",
    "                ls.insert(0, \"timestamp\")\n",
    "            else:\n",
    "                ls = [\"timestamp\", ls[i]]\n",
    "\n",
    "            df = df[ls]\n",
    "\n",
    "        else:\n",
    "            cal_avg = 0\n",
    "            dic = {\n",
    "                1: \"wristPS\",\n",
    "                2: \"wristFE\",\n",
    "                3: \"wristUDRD\",\n",
    "                4: [\n",
    "                    \"fingerPalm\",\n",
    "                    \"fingerIndex\",\n",
    "                    \"fingerMiddle\",\n",
    "                    \"fingerRing\",\n",
    "                    \"fingerPinky\",\n",
    "                ],\n",
    "                5: \"wristPStrans\",\n",
    "                6: \"wristFEtrans\",\n",
    "                7: \"wristUDRDtrans\",\n",
    "                8: [\n",
    "                    \"fingerPalmtrans\",\n",
    "                    \"fingerIndextrans\",\n",
    "                    \"fingerMiddletrans\",\n",
    "                    \"fingerRingtrans\",\n",
    "                    \"fingerPinkytrans\",\n",
    "                ],\n",
    "            }\n",
    "            print(pd.DataFrame.from_dict(dic, orient=\"index\"))\n",
    "            query = input(\n",
    "                \"Select columns to export by index (press 0 to select all):\"\n",
    "            ).split()\n",
    "\n",
    "            if query == [\"0\"]:\n",
    "                df = df.iloc[:, np.r_[2, 5:21]]\n",
    "                ls = list(df.columns()) + [\"fingerAvg\"]\n",
    "                cal_avg += 1\n",
    "            else:\n",
    "                ls = [\"timestamp\"]\n",
    "                for i in query:\n",
    "                    if int(i) == 4:\n",
    "                        ls = ls + dic[int(i)]\n",
    "                    elif int(i) == 8:\n",
    "                        ls = ls + dic[int(i)]\n",
    "                        cal_avg += 1\n",
    "                    else:\n",
    "                        ls.append(dic[int(i)])\n",
    "                df = df[ls]\n",
    "\n",
    "        if cal_avg == 1:\n",
    "            df[\"fingerAvg\"] = df[dic[8]].apply(np.mean, axis=1)\n",
    "            ls.append(\"fingerAvg\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        df = df.dropna(axis=0).reset_index(drop = True)\n",
    "\n",
    "        return df, ls\n",
    "\n",
    "    def show_graph(self, sub = False, peak=0, save = False):\n",
    "\n",
    "        \"\"\"Visualize sensordata as a plot (seaborn). \n",
    "\n",
    "        Args:\n",
    "            sub: T/F. 훈련에 쓰이는 센서데이터 외 센서데이터 사용 여부 (e.g. POUR_WINE 에서 trans Forearm S/P 값 외의 센서값 사용 시 True 입력)\n",
    "            peak: int. peak detection algorithm 선택.\n",
    "            save: T/F. 저장 여부\n",
    "\n",
    "        Returns:\n",
    "            seaborn plot. \n",
    "            (if save == True, html file named '{patient id}_{mission_id}.png' is saved under folder named 'images'\n",
    "        \"\"\"\n",
    "\n",
    "        df, ls = self.get_df(sub=sub)\n",
    "        df_plot = pd.melt(df, id_vars=[\"timestamp\"], value_vars=ls[1:])\n",
    "\n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(40, 20))\n",
    "        sns.set(style=\"ticks\", palette=\"muted\", font_scale=1.8)\n",
    "        if self.treatment == 1:\n",
    "            plt.suptitle(\n",
    "                \"Patient#: \"\n",
    "                + str(self.pid)\n",
    "                + \"\\n Content: \"\n",
    "                + str(self.cid)[12:]\n",
    "                + \" (\"\n",
    "                + str(self.tt)[12:]\n",
    "                + \")\"\n",
    "                + \"\\n Mission#: \"\n",
    "                + str(self.mid)\n",
    "            )\n",
    "        elif self.treatment == 0:\n",
    "            plt.suptitle(\n",
    "                \"Control Group with Content: \"\n",
    "                + str(self.cid)[12:]\n",
    "                + \" (\"\n",
    "                + str(self.tt)[12:]\n",
    "                + \")\"\n",
    "                + \"\\n Mission#: \"\n",
    "                + str(self.mid)\n",
    "            )\n",
    "        if \"fingerAvg\" in ls:\n",
    "            fig = plt.figure(figsize=(40, 40))\n",
    "            ax1 = fig.add_subplot(211)\n",
    "            ax2 = fig.add_subplot(212)\n",
    "\n",
    "            sns.lineplot(\n",
    "                data=df_plot,\n",
    "                x=\"timestamp\",\n",
    "                y=\"value\",\n",
    "                hue=\"variable\",\n",
    "                dashes=False,\n",
    "                ax=ax1,\n",
    "            )\n",
    "            sns.lineplot(data=df, x=\"timestamp\", y=\"fingerAvg\", ax=ax2)\n",
    "\n",
    "            ax1.set(ylabel=\"Value\", title=\"For each finger\")\n",
    "            ax2.set(xlabel=\"Value\", title=\"Average of fingers\")\n",
    "        else:\n",
    "            sns.lineplot(\n",
    "                x=\"timestamp\", y=\"value\", data=df_plot, hue=\"variable\", dashes=False\n",
    "            )\n",
    "\n",
    "        if sub == 0:\n",
    "            if self.trans == 1:\n",
    "                plt.axhspan(self.range[0], self.range[1], facecolor=\"k\", alpha=0.05)\n",
    "\n",
    "        if peak == 1:\n",
    "            df_peak = self.detect_peak()\n",
    "        elif peak == 2:\n",
    "            df_peak = self.detect_final_peak()\n",
    "        elif peak == 3:\n",
    "            df_peak = self.detect_modified_peak()\n",
    "        elif peak == 4:\n",
    "            df_peak = self.detect_modified_s_peak()\n",
    "        else:\n",
    "            df_peak = []\n",
    "\n",
    "        if len(df_peak) < 1:\n",
    "            print(\"No detected peak\")\n",
    "        else:\n",
    "            for index, value in df_peak.iteritems():\n",
    "                plt.axvspan(\n",
    "                    df.loc[value[0], \"timestamp\"],\n",
    "                    df.loc[value[-1], \"timestamp\"],\n",
    "                    facecolor=\"skyblue\",\n",
    "                    alpha=0.2,\n",
    "                )\n",
    "\n",
    "        if save == 1:\n",
    "            plt.savefig(\n",
    "                \"../../images/\" + str(self.pid) + \"_\" + str(self.mid) + \".png\",\n",
    "                quality=50,\n",
    "            )\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def show_plotly(self, sub = False, peak = 0, save = False):\n",
    "\n",
    "        \"\"\"Visualize sensordata as an interactive plot (plotly). \n",
    "\n",
    "        Args:\n",
    "            sub: T/F. 훈련에 쓰이는 센서데이터 외 센서데이터 사용 여부 (e.g. POUR_WINE 에서 trans Forearm S/P 값 외의 센서값 사용 시 True 입력)\n",
    "            peak: int. peak detection algorithm 선택.\n",
    "            save: T/F. 저장 여부\n",
    "\n",
    "        Returns:\n",
    "            Plotly plot. \n",
    "            (if save == True, html file named '{patient id}_{mission_id}.html' is saved under folder named 'images'\n",
    "        \"\"\"\n",
    "\n",
    "        df, ls = self.get_df(sub=sub)\n",
    "        print(ls)\n",
    "\n",
    "        template = \"plotly_white\"\n",
    "        if self.tt == \"SMART_GLOVE_FINGER_FLEX_EXT\":\n",
    "\n",
    "            fig = go.Figure(layout=go.Layout(hovermode=\"x\"))\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=df.timestamp, y=df[ls[1]], mode=\"lines\", name=\"Palm\")\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=df.timestamp, y=df[ls[2]], mode=\"lines\", name=\"Index\")\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=df.timestamp, y=df[ls[3]], mode=\"lines\", name=\"Middle\")\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=df.timestamp, y=df[ls[4]], mode=\"lines\", name=\"Ring\")\n",
    "            )\n",
    "            fig.add_trace(\n",
    "                go.Scatter(x=df.timestamp, y=df[ls[5]], mode=\"lines\", name=\"Pinky\")\n",
    "            )\n",
    "            fig.update_layout(\n",
    "                shapes=[\n",
    "                    go.layout.Shape(\n",
    "                        type=\"rect\",\n",
    "                        x0=df[\"timestamp\"].min(),\n",
    "                        y0=self.range[0],\n",
    "                        x1=df[\"timestamp\"].max(),\n",
    "                        y1=self.range[1],\n",
    "                        fillcolor=\"whitesmoke\",\n",
    "                        opacity=0.25,\n",
    "                        layer=\"below\",\n",
    "                        line_width=0,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            fig = px.line(df, x=\"timestamp\", y=ls[1], template=template)\n",
    "            fig.update_layout(\n",
    "                shapes=[\n",
    "                    go.layout.Shape(\n",
    "                        type=\"rect\",\n",
    "                        x0=df[\"timestamp\"].min(),\n",
    "                        y0=self.range[0],\n",
    "                        x1=df[\"timestamp\"].max(),\n",
    "                        y1=self.range[1],\n",
    "                        fillcolor=\"whitesmoke\",\n",
    "                        opacity=0.25,\n",
    "                        layer=\"below\",\n",
    "                        line_width=0,\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        figname = \"../images/\" + str(self.pid) + \"_\" + str(self.mid) + \".html\"\n",
    "\n",
    "        if self.treatment == 1:\n",
    "            fig.update_layout(\n",
    "                title_text=\"Patient#: \"\n",
    "                + str(self.pid)\n",
    "                + \"\\n Content: \"\n",
    "                + str(self.cid)[12:]\n",
    "                + \"\\n Mission#: \"\n",
    "                + str(self.mid),\n",
    "                template=template,\n",
    "            )\n",
    "        elif self.treatment == 0:\n",
    "            fig.update_layout(\n",
    "                title_text=\"Control Group with Content: \"\n",
    "                + str(self.cid)[11:]\n",
    "                + \"\\n Mission#: \"\n",
    "                + str(self.mid),\n",
    "                template=template,\n",
    "            )\n",
    "        fig.show()\n",
    "\n",
    "        if save == 1:\n",
    "            fig.write_html(figname)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def get_speed(self, sub=False, filtering=False):\n",
    "\n",
    "        \"\"\"센서데이터를 기반으로 한 속도데이터셋을 생성한다. \n",
    "\n",
    "        Args:\n",
    "            sub: T/F. 훈련에 쓰이는 센서데이터 외 센서데이터 사용 여부 (e.g. POUR_WINE 에서 trans Forearm S/P 값 외의 센서값 사용 시 True 입력)\n",
    "            filtering: T/F. butterworth low pass filter 적용 여부\n",
    "\n",
    "        Returns:\n",
    "            Pandas Series/DataFrame. sensordata를 한번 미분한 속도(IMU: 각속도, Bending sensor: 굽힘 속도) 데이터. \n",
    "        \n",
    "        Raises:\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        df, ls = self.get_df(sub=sub)\n",
    "\n",
    "        # Calculate approximate dt for sampling rate (actual value will have its own distribution, but approximate is enough)\n",
    "        timedelta = 0.001 * np.mean(\n",
    "            np.gradient(df[\"timestamp\"]).astype(\"timedelta64[ms]\").astype(\"float\")\n",
    "        )\n",
    "\n",
    "        if len(ls) == 2:\n",
    "            d = False\n",
    "        elif len(ls) > 2:\n",
    "            d = True\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Number of columns in EMR dataframe is ambiguous. Check it\"\n",
    "            )\n",
    "\n",
    "        if filtering == 0:\n",
    "            data = get_derivative(df[ls[1:]].dropna(axis=0), timedelta=timedelta, d=d)\n",
    "\n",
    "        elif filtering == 1:\n",
    "            b, a = butterworth_filter(5, 5, timedelta)\n",
    "\n",
    "            if d:\n",
    "                data = get_derivative(\n",
    "                    df[ls[1:]].dropna(axis=0), timedelta=timedelta, d=d\n",
    "                )\n",
    "                for i in data.columns:\n",
    "                    data[i] = spsg.filtfilt(b, a, data[i])\n",
    "            else:\n",
    "                data = pd.Series(\n",
    "                    spsg.filtfilt(\n",
    "                        b,\n",
    "                        a,\n",
    "                        get_derivative(\n",
    "                            df[ls[1:]].dropna(axis=0), timedelta=timedelta, d=d\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def show_speed(self, sub=False, filtering = False, peak=0):\n",
    "\n",
    "        \"\"\"Visualize speed data as a plot (seaborn). \n",
    "\n",
    "        Args:\n",
    "            sub: T/F. 훈련에 쓰이는 센서데이터 외 센서데이터 사용 여부 (e.g. POUR_WINE 에서 trans Forearm S/P 값 외의 센서값 사용 시 True 입력)\n",
    "            filtering = \n",
    "            peak: int. peak detection algorithm 선택.\n",
    "\n",
    "        Returns:\n",
    "            seaborn plot. \n",
    "        \"\"\"\n",
    "\n",
    "        df_speed = self.get_speed(sub=sub, filtering=filtering)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(30, 15))\n",
    "        if self.treatment == 1:\n",
    "            plt.title(\n",
    "                \"Speed Plot of Patient#: \"\n",
    "                + str(self.pid)\n",
    "                + \"\\n Content: \"\n",
    "                + str(self.cid)[12:]\n",
    "                + \"\\n Mission#: \"\n",
    "                + str(self.mid)\n",
    "            )\n",
    "        elif self.treatment == 0:\n",
    "            plt.title(\n",
    "                \"Speed Plot of Control Group with Content: \"\n",
    "                + str(self.cid)[11:]\n",
    "                + \"\\n Mission#: \"\n",
    "                + str(self.mid)\n",
    "            )\n",
    "\n",
    "        if peak == 1:\n",
    "            df_peak = self.detect_peak()\n",
    "        elif peak == 2:\n",
    "            df_peak = self.detect_modified_peak()\n",
    "        else:\n",
    "            df_peak = []\n",
    "\n",
    "        if len(df_peak) < 1:\n",
    "            print(\"No detected peak\")\n",
    "        else:\n",
    "            for index, value in df_peak.iteritems():\n",
    "                # print(row)\n",
    "                plt.axvspan(value[0], value[-1], facecolor=\"c\", alpha=0.1)\n",
    "\n",
    "        sns.lineplot(data=df_speed, dashes=False)\n",
    "\n",
    "    def get_acceleration(self, sub=0, filtering=0):\n",
    "\n",
    "        \"\"\"Visualize speed data as a plot (seaborn). \n",
    "\n",
    "        Args:\n",
    "            sub: T/F. 훈련에 쓰이는 센서데이터 외 센서데이터 사용 여부 (e.g. POUR_WINE 에서 trans Forearm S/P 값 외의 센서값 사용 시 True 입력)\n",
    "            filtering = \n",
    "            peak: int. peak detection algorithm 선택.\n",
    "\n",
    "        Returns:\n",
    "            seaborn plot. \n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        - 해당 exercise mission result의 sensordata를 미분한 속도 값을 시각화한다. <br> (x축: timestamp, y축: 해당 mission에 알맞은 training type에 해당하는 sensordata의 미분값(속도)) <br> *note: 미분은 np.gradient() 함수 이용, 위 get_derivative() 함수 참고*\n",
    "        - input: Mission ID, 환자(control, 'p' 혹은 1)/일반인(experiment, 'g' or 0) 여부\n",
    "        - output: \n",
    "        - Plot (seaborn): \n",
    "            - (Blue) with no filter\n",
    "            - (Red) with Butterworth lowpass filter with certain order (now 5) and cutoff freq (now 5) \n",
    "        - 해당 mission id 및 환자/일반인에 대한 기본 정보 출력(print): called by get_context()\n",
    "        \"\"\"\n",
    "\n",
    "        df_speed = self.get_speed(sub=sub, filtering=filtering)\n",
    "\n",
    "        # Calculate approximate dt for sampling rate (actual value will have its own distribution, but approximate is enough)\n",
    "        timedelta = self.timedelta\n",
    "\n",
    "        if isinstance(df_speed, pd.Series):\n",
    "            d = False\n",
    "        elif len(df_speed.columns()) >= 2:\n",
    "            d = True\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Number of columns in EMR dataframe is ambiguous. Check it\"\n",
    "            )\n",
    "\n",
    "        if filtering == 0:\n",
    "            data = get_derivative(df_speed.dropna(axis=0), timedelta=timedelta, d=d)\n",
    "\n",
    "        elif filtering == 1:\n",
    "\n",
    "            b, a = butterworth_filter(5, 5, timedelta)\n",
    "\n",
    "            if d:\n",
    "                data = get_derivative(df_speed.dropna(axis=0), timedelta=timedelta, d=d)\n",
    "                for colname in data.columns:\n",
    "                    data[colname] = spsg.filtfilt(b, a, data[colname])\n",
    "            else:\n",
    "                data = pd.Series(\n",
    "                    spsg.filtfilt(\n",
    "                        b,\n",
    "                        a,\n",
    "                        get_derivative(\n",
    "                            df_speed.dropna(axis=0), timedelta=timedelta, d=d\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def show_acceleration(self, sub=False, filtering=False, peak=0):\n",
    "\n",
    "        \"\"\"Visualize acceleration data as a plot (seaborn). \n",
    "\n",
    "        Args:\n",
    "            sub: T/F. 훈련에 쓰이는 센서데이터 외 센서데이터 사용 여부 (e.g. POUR_WINE 에서 trans Forearm S/P 값 외의 센서값 사용 시 True 입력)\n",
    "            filtering = \n",
    "            peak: int. peak detection algorithm 선택.\n",
    "\n",
    "        Returns:\n",
    "            seaborn plot. \n",
    "        \"\"\"\n",
    "\n",
    "        acceleration_data = self.get_acceleration(sub=sub, filtering=filtering)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(30, 15))\n",
    "        if self.treatment == 1:\n",
    "            plt.title(\n",
    "                \"Acceleration Plot of Patient#: \"\n",
    "                + str(self.pid)\n",
    "                + \"\\n Content: \"\n",
    "                + str(self.cid)[12:]\n",
    "                + \"\\n Mission#: \"\n",
    "                + str(self.mid)\n",
    "            )\n",
    "        elif self.treatment == 0:\n",
    "            plt.title(\n",
    "                \"Acceleration Plot of Control Group with Content: \"\n",
    "                + str(self.cid)[11:]\n",
    "                + \"\\n Mission#: \"\n",
    "                + str(self.mid)\n",
    "            )\n",
    "\n",
    "        if peak == 1:\n",
    "            df_peak = self.detect_peak()\n",
    "        elif peak == 2:\n",
    "            df_peak = self.detect_modified_peak()\n",
    "        else:\n",
    "            df_peak = []\n",
    "\n",
    "        if len(df_peak) < 1:\n",
    "            print(\"No detected peak\")\n",
    "        else:\n",
    "            for index, value in df_peak.iteritems():\n",
    "                # print(row)\n",
    "                plt.axvspan(value[0], value[-1], facecolor=\"c\", alpha=0.1)\n",
    "\n",
    "        sns.lineplot(data=acceleration_data, dashes=False)\n",
    "\n",
    "    def detect_peak(self, time=168):\n",
    "\n",
    "        \"\"\"Detect peak algorithm. \n",
    "\n",
    "        Args:\n",
    "            time: maintain time to success motion. (5 seconds in general ~ 168 data points by experience)\n",
    "\n",
    "        Returns:\n",
    "            seaborn plot. \n",
    "        \"\"\"\n",
    "\n",
    "        if (\n",
    "            self.tt == \"SMART_GLOVE_FOREARM_SUP_PRONATION\"\n",
    "            or self.tt == \"SMART_GLOVE_WRIST_FLEX_EXT_AG\"\n",
    "        ):\n",
    "            df, ls = self.get_df()\n",
    "\n",
    "            meta = []\n",
    "            window = []\n",
    "            stack_val = []\n",
    "            stack_idx = []\n",
    "            num_lackpeak = 0  # calibration range는 넘었으나 5초 유지를 못한 경우 count\n",
    "\n",
    "            for row in df.itertuples():\n",
    "                if len(window) < 2:\n",
    "                    # window에 element가 2개가 채워질 때까지는 그냥 채움\n",
    "                    window.append(row[2])\n",
    "                    if len(window) == 2:\n",
    "                        # window에 element가 2개가 되고 마지막 element가 ROM calrange 바깥에 있으면 stack하기 시작\n",
    "                        if window[1] >= self.range[1] or window[1] <= self.range[0]:\n",
    "                            stack_val.append(row[2])\n",
    "                            stack_idx.append(row.Index)\n",
    "                else:\n",
    "                    del window[0]\n",
    "                    window.append(row[2])\n",
    "                    if (window[0] >= self.range[0]) and (self.range[0] >= window[1]):\n",
    "                        # Start Stacking (Case A)\n",
    "                        if len(stack_val) == len(stack_idx) == 0:\n",
    "                            stack_val.append(row[2])\n",
    "                            stack_idx.append(row.Index)\n",
    "\n",
    "                        else:\n",
    "                            print(\n",
    "                                \"Something is wrong (start 1)\",\n",
    "                                self.mid,\n",
    "                                window,\n",
    "                                row.Index,\n",
    "                                df.loc[row.Index, \"timestamp\"],\n",
    "                            )\n",
    "\n",
    "                            if abs(window[1] - window[0]) > (\n",
    "                                self.range[1] - self.range[0]\n",
    "                            ):\n",
    "                                print(\"Sensor Error\")\n",
    "                                stack_val.append(row[2])\n",
    "                                stack_idx.append(row.Index)\n",
    "                                if len(stack_idx) >= time:\n",
    "                                    meta.append([stack_idx[0], stack_idx[-1]])\n",
    "                                else:\n",
    "                                    pass\n",
    "                                stack_val = [row[2]]\n",
    "                                stack_idx = [row.Index]\n",
    "                            else:\n",
    "                                print(\"Fuck, what is this error?\")\n",
    "\n",
    "                    elif (window[0] <= self.range[0]) and (self.range[0] <= window[1]):\n",
    "                        # Stop Stacking (Case B)\n",
    "                        if (len(stack_val) != 0) or (len(stack_idx) != 0):\n",
    "                            stack_val.append(row[2])\n",
    "                            stack_idx.append(row.Index)\n",
    "                            if len(stack_idx) >= time:\n",
    "                                meta.append([stack_idx[0], stack_idx[-1]])\n",
    "                            else:\n",
    "                                num_lackpeak += 1\n",
    "                            stack_val = []\n",
    "                            stack_idx = []\n",
    "                        else:\n",
    "                            print(\n",
    "                                \"Something is wrong (stop 1)\",\n",
    "                                self.mid,\n",
    "                                window,\n",
    "                                row.Index,\n",
    "                                df.loc[row.Index, \"timestamp\"],\n",
    "                            )\n",
    "                            # if abs(window[1] - window[0]) > (self.range[1] - self.range[0]):\n",
    "                            # stack_val.append(row[2])\n",
    "                            # stack_idx.append(row.Index)\n",
    "                        # print(stack_val, stack_idx)\n",
    "\n",
    "                    elif (window[0] <= self.range[1]) and (self.range[1] <= window[1]):\n",
    "                        # print(\"stack start: case 2\", idx)\n",
    "                        if len(stack_val) == len(stack_idx) == 0:\n",
    "                            stack_val.append(row[2])\n",
    "                            stack_idx.append(row.Index)\n",
    "\n",
    "                        else:\n",
    "                            print(\n",
    "                                \"Something is wrong (start 2)\",\n",
    "                                self.mid,\n",
    "                                window,\n",
    "                                row.Index,\n",
    "                                df.loc[row.Index, \"timestamp\"],\n",
    "                            )\n",
    "\n",
    "                    elif (window[0] >= self.range[1]) and (self.range[1] >= window[1]):\n",
    "                        # print(\"stack stop: case 2\", idx)\n",
    "                        if len(stack_val) == len(stack_idx) == 0:\n",
    "                            stack_val.append(row[2])\n",
    "                            stack_idx.append(row.Index)\n",
    "                            if len(stack_idx) >= time:\n",
    "                                meta.append([stack_idx[0], stack_idx[-1]])\n",
    "                            else:\n",
    "                                num_lackpeak += 1\n",
    "                        else:\n",
    "                            print(\n",
    "                                \"Something is wrong (stop 2)\",\n",
    "                                self.mid,\n",
    "                                window,\n",
    "                                row.Index,\n",
    "                                df.loc[row.Index, \"timestamp\"],\n",
    "                            )\n",
    "                        # print(stack_val, stack_idx)\n",
    "                        stack_val = []\n",
    "                        stack_idx = []\n",
    "\n",
    "                    else:\n",
    "                        if len(stack_val) == len(stack_idx) == 0:\n",
    "                            stack_val.append(row[2])\n",
    "                            stack_idx.append(row.Index)\n",
    "                            # print(\"stack continue: \", idx)\n",
    "\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "            if len(stack_val) == len(stack_idx) == 0:\n",
    "                # this is for the last stack which is detected as a peak\n",
    "                if len(stack_idx) >= time:\n",
    "                    meta.append([stack_idx[0], stack_idx[-1]])\n",
    "\n",
    "            peak_idx = pd.Series(meta)\n",
    "            peak_idx.columns = [\"peak_idx\"]\n",
    "            self.num_lackpeak = num_lackpeak\n",
    "            return peak_idx\n",
    "        elif self.tt == \"SMART_GLOVE_WRIST_DEVIATION_EG\":\n",
    "            df, ls = self.get_df()\n",
    "\n",
    "            meta = []\n",
    "            window = []\n",
    "            window_idx = []\n",
    "            stack_val = []\n",
    "            stack_idx = []\n",
    "\n",
    "            for row in df.itertuples():\n",
    "                if len(window) < time:\n",
    "                    # window에 element가 x개가 채워질 때까지는 그냥 채움\n",
    "                    window.append(row[2])\n",
    "                    window_idx.append(row.Index)\n",
    "                    if len(window) == time:\n",
    "                        if (\n",
    "                            check_treasure_range(window, self.effective_range())\n",
    "                            is True\n",
    "                        ):\n",
    "                            # stack_val.apppend(window)\n",
    "                            stack_idx.append([window_idx[0], window_idx[-1]])\n",
    "                else:\n",
    "                    del window[0]\n",
    "                    del window_idx[0]\n",
    "                    window.append(row[2])\n",
    "                    window_idx.append(row.Index)\n",
    "                    # Case 1: 아예 처음으로 stack 시작\n",
    "                    if check_treasure_range(window, self.effective_range()) is True:\n",
    "                        if (len(stack_val) != 0) or (len(stack_idx) != 0):\n",
    "                            # stack_val.append(window)\n",
    "                            stack_idx.append([window_idx[0], window_idx[-1]])\n",
    "                        # Case 2: 기존 stack에 이어서 붙여야 할 때\n",
    "                        else:\n",
    "                            if stack_idx[-1][0] < window_idx[0] < stack_idx[-1][1]:\n",
    "                                # stack_val[-1].append(row[2])\n",
    "                                del stack_idx[-1][-1]\n",
    "                                stack_idx[-1].append(row.Index)\n",
    "                            else:\n",
    "                                # stack_val.append(window)\n",
    "                                stack_idx.append([window_idx[0], window_idx[-1]])\n",
    "                    # Case 3: Stack이 끝났을 때\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "            return pd.Series(stack_idx)\n",
    "\n",
    "        else:\n",
    "            print(\"Inappropriate game contents to detect peak (for now)\")\n",
    "            empty_list = []\n",
    "            return empty_list\n",
    "\n",
    "    def detect_modified_peak(self, filtering=1):\n",
    "\n",
    "        \"\"\"Visualize speed data as a plot (seaborn). \n",
    "\n",
    "        Args:\n",
    "            sub: T/F. 훈련에 쓰이는 센서데이터 외 센서데이터 사용 여부 (e.g. POUR_WINE 에서 trans Forearm S/P 값 외의 센서값 사용 시 True 입력)\n",
    "            filtering = \n",
    "            peak: int. peak detection algorithm 선택.\n",
    "\n",
    "        Returns:\n",
    "            seaborn plot. \n",
    "        \"\"\"\n",
    "\n",
    "        df_peak = self.detect_peak()\n",
    "        df_acceleration = self.get_acceleration(filtering=filtering)\n",
    "        if len(df_peak) < 1:\n",
    "            return df_peak\n",
    "        else:\n",
    "            for index, value in df_peak.iteritems():\n",
    "                i = value[0]\n",
    "                if i != 0:\n",
    "                    while np.sign(df_acceleration.loc[i]) == np.sign(\n",
    "                        df_acceleration.loc[i - 1]\n",
    "                    ):\n",
    "                        i += 1\n",
    "                        value.pop(0)\n",
    "                        value.insert(0, i)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                j = value[-1]\n",
    "                if j != df_acceleration.index[-1]:\n",
    "                    while np.sign(df_acceleration.loc[j]) == np.sign(\n",
    "                        df_acceleration.loc[j + 1]\n",
    "                    ):\n",
    "                        j -= 1\n",
    "                        value.pop(-1)\n",
    "                        value.append(j)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            return df_peak\n",
    "\n",
    "    def detect_modified_s_peak(self, filtering = True):\n",
    "        \"\"\"Detect peaks by speed zero crossing algorithm in addition to the original algorithm.\n",
    "\n",
    "        Args:\n",
    "            filtering: butterworth low pass filter.\n",
    "            \n",
    "        Returns:\n",
    "            Pandas Series consists of Peak indices (start, end). \n",
    "        \"\"\"\n",
    "        \n",
    "        df_peak = self.detect_peak()\n",
    "        df_speed = self.get_speed(filtering=filtering)\n",
    "        if len(df_peak) < 1:\n",
    "            return df_peak\n",
    "        else:\n",
    "            for index, value in df_peak.iteritems():\n",
    "                i = value[0]\n",
    "                if i != 0:\n",
    "                    while np.sign(df_speed.loc[i]) == np.sign(df_speed.loc[i - 1]):\n",
    "                        i += 1\n",
    "                        value.pop(0)\n",
    "                        value.insert(0, i)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                j = value[-1]\n",
    "                if j != df_speed.index[-1]:\n",
    "                    while np.sign(df_speed.loc[j]) == np.sign(df_speed.loc[j + 1]):\n",
    "                        j -= 1\n",
    "                        value.pop(-1)\n",
    "                        value.append(j)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            return df_peak\n",
    "\n",
    "    def detect_final_peak(self, filtering = False):\n",
    "\n",
    "        \"\"\"Detect peaks by averaging the results of speed zero crossing algorithm and acc zero crossing algorithm.\n",
    "\n",
    "        Args:\n",
    "            filtering: butterworth low pass filter.\n",
    "            \n",
    "        Returns:\n",
    "            Pandas Series consists of Peak indices (start, end). \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        df_mod_peak = self.detect_modified_peak(filtering=filtering)\n",
    "        df_mod_s_peak = self.detect_modified_s_peak(filtering=filtering)\n",
    "        if len(df_mod_peak) == len(df_mod_s_peak):\n",
    "            df_final = pd.concat([df_mod_peak, df_mod_s_peak], axis=1)\n",
    "            df_final[\"final\"] = df_final.apply(\n",
    "                lambda row: [\n",
    "                    int((row[0][0] + row[1][0] + 1) / 2),\n",
    "                    int((row[0][1] + row[1][1]) / 2),\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "        else:\n",
    "            print(\"df_peak is not consistent\")\n",
    "        return df_final[\"final\"]\n",
    "\n",
    "    def detect_gap(self, mod=0):\n",
    "\n",
    "        \"\"\"Detect gaps in peak to peak. \n",
    "\n",
    "        Args:\n",
    "            mod: int. peak detection algorithm\n",
    "\n",
    "        Returns:\n",
    "            Pandas Series with indices of gap (start, end). \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        if mod == 0:\n",
    "            df_peak = self.detect_final_peak(filtering=1)\n",
    "        elif mod == 1:\n",
    "            df_peak = self.detect_modified_peak()\n",
    "        else:\n",
    "            df_peak = self.detect_peak()\n",
    "\n",
    "        meta_stack = []\n",
    "        stack = []\n",
    "        for index, value in df_peak.iteritems():\n",
    "            if len(stack) == 0:\n",
    "                stack.append(value[-1])\n",
    "                continue\n",
    "            elif len(stack) == 1:\n",
    "                stack.append(value[0])\n",
    "                meta_stack.append(stack)\n",
    "                stack = []\n",
    "                stack.append(value[-1])\n",
    "                continue\n",
    "            else:\n",
    "                print(\"stacking error when finding gap\")\n",
    "        gap_idx = pd.Series(meta_stack)\n",
    "        gap_idx.columns = [\"gap_idx\"]\n",
    "        return gap_idx\n",
    "\n",
    "    def peak_gap_info(self, p_or_g, mod=0):\n",
    "\n",
    "        \"\"\"Get list of indices, sensordata, speed, acceleration dataset of peaks and gaps. \n",
    "\n",
    "        Args:\n",
    "            p_or_g: str. in ('p', 'peak', 'g', 'gap').\n",
    "            mod: int. peak detection algorithm.\n",
    "\n",
    "        Returns:\n",
    "            Pandas DataFrame.\n",
    "        \"\"\"        \n",
    "\n",
    "        if p_or_g == \"p\" or p_or_g == \"peak\":\n",
    "            if mod == 0:\n",
    "                series = self.detect_final_peak(filtering=1)\n",
    "            elif mod == 1:\n",
    "                series = self.detect_modified_peak()\n",
    "            else:\n",
    "                series = self.detect_peak()\n",
    "        elif p_or_g == \"g\" or p_or_g == \"gap\":\n",
    "            series = self.detect_gap(mod=mod)\n",
    "\n",
    "        df_raw, ls = self.get_df()\n",
    "        df_speed = self.get_speed()\n",
    "        df_acceleration = self.get_acceleration()\n",
    "\n",
    "        meta_degree = []\n",
    "        meta_speed = []\n",
    "        meta_acceleration = []\n",
    "\n",
    "        for index, value in series.iteritems():\n",
    "            ls_degree = []\n",
    "            ls_speed = []\n",
    "            ls_acceleration = []\n",
    "            for i in range(value[0], int(value[-1] + 1)):\n",
    "                ls_degree.append(df_raw.iloc[i, 1])\n",
    "                ls_speed.append(df_speed[i])\n",
    "                ls_acceleration.append(df_acceleration[i])\n",
    "            meta_degree.append(ls_degree)\n",
    "            meta_speed.append(ls_speed)\n",
    "            meta_acceleration.append(ls_acceleration)\n",
    "\n",
    "        df = pd.concat(\n",
    "            [\n",
    "                series,\n",
    "                pd.Series(meta_degree),\n",
    "                pd.Series(meta_speed),\n",
    "                pd.Series(meta_acceleration),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        df.columns = [\"idx\", \"angle\", \"speed\", \"acceleration\"]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def general_feature(self):\n",
    "\n",
    "        \"\"\"Calculate features for exercise mission result (unit of EMR). \n",
    "\n",
    "        Returns:\n",
    "            dict. or dataframe consists of all game-level biomarkers\n",
    "        \"\"\"\n",
    "\n",
    "        df_raw, ls = self.get_df()\n",
    "        df_speed = self.get_speed(filtering=1)\n",
    "        df_acc = self.get_speed(filtering=1)\n",
    "\n",
    "        # 0. Preset\n",
    "        target_playtime = {\"target playtime\": self.target_playtime}\n",
    "        target_maintaintime = {\"target maintain time\": self.target_maintaintime}\n",
    "        target_success_count = {\"target success count\": self.target_success_count}\n",
    "\n",
    "        # 1. General Info\n",
    "        playtime = {\n",
    "            \"playtime\": round(\n",
    "                (df_raw[\"timestamp\"].max() - df_raw[\"timestamp\"].min()).total_seconds(),\n",
    "                2,\n",
    "            )\n",
    "        }\n",
    "        playtime_record = {\"playtime by record\": self.playtime}\n",
    "        playtime_ratio = {\n",
    "            \"playtime ratio\": round((self.playtime / self.target_playtime), 2)\n",
    "        }\n",
    "        finished_way = {\"finish type\": self.finished_way()}\n",
    "        feedback = {\"feedback\": self.feedback}\n",
    "\n",
    "        # 2. AROM\n",
    "        if self.tt == \"SMART_GLOVE_FINGER_FLEX_EXT\":\n",
    "            calibrated_arom = {\"Calibration AROM\": \"N/A\"}\n",
    "            success_arom = {\"Success AROM\": self.range}\n",
    "            max_arom = {\"Max AROM\": \"N/A\"}\n",
    "        else:\n",
    "            calibrated_arom = {\"Calibration AROM\": self.cal_range[0]}\n",
    "            success_arom = {\"Success AROM\": self.range}\n",
    "            max_arom = {\n",
    "                \"Max AROM\": [\n",
    "                    np.percentile(df_raw[ls[1]][df_raw[ls[1]] < self.range[0]], 50),\n",
    "                    np.percentile(df_raw[ls[1]][df_raw[ls[1]] > self.range[1]], 50),\n",
    "                ]\n",
    "            }\n",
    "\n",
    "        # 3. Speed\n",
    "        max_speed = {\n",
    "            \"Max Speed\": [np.percentile(df_speed, 5), np.percentile(df_speed, 95)]\n",
    "        }\n",
    "\n",
    "        # 4. Coordination\n",
    "        # 4-1. Motion Success\n",
    "        success_count = {\"Success Count\": self.success_count}\n",
    "        achieve_ratio = {\"Achieve Ratio\": self.achieve_ratio}\n",
    "        earned_star = {\"Star\": self.earned_star}\n",
    "        time_per_success = {\"time per success\": self.playtime / self.success_count}\n",
    "        h_idx = {\"H-index\": self.h_index(thres_v=3, thres_t=3)}\n",
    "\n",
    "        # 4-2. Smoothness\n",
    "        nmu = {\n",
    "            \"No. Movement Unit\": zero_crossing(df_acc, threshold=10)\n",
    "            / self.success_count\n",
    "        }\n",
    "        log_jerk = {\n",
    "            \"Log Dimensionleimss Jerk\": log_dimensionless_jerk(\n",
    "                df_speed, 1 / self.timedelta\n",
    "            )\n",
    "        }\n",
    "        sp_arc = {\"SPARC\": sparc(df_speed, 1 / self.timedelta)[0]}\n",
    "\n",
    "        # 4-3. Correlation\n",
    "        if self.tt == \"SMART_GLOVE_FINGER_FLEX_EXT\":\n",
    "            df_raw[\"avg\"] = df[ls[1:]].mean(axis=1)\n",
    "            for i in range(1, 6):\n",
    "                column = \"avg\" + str(i)\n",
    "                df_raw[column] = ((5 * df_raw[\"avg\"]) - df_raw[df_raw.columns[i]]) / 4\n",
    "            finger_coordination = {\n",
    "                \"finger coordination\": np.diag(df_raw.corr().iloc[0:5, -5:])\n",
    "            }\n",
    "        else:\n",
    "            finger_coordination = {\"finger coordination\": \"N/A\"}\n",
    "\n",
    "        # 5. Endurance\n",
    "\n",
    "        feature_list = [\n",
    "            target_playtime,\n",
    "            target_maintaintime,\n",
    "            target_success_count,\n",
    "            playtime,\n",
    "            playtime_record,\n",
    "            playtime_ratio,\n",
    "            finished_way,\n",
    "            feedback,\n",
    "            calibrated_arom,\n",
    "            success_arom,\n",
    "            max_arom,\n",
    "            max_speed,\n",
    "            success_count,\n",
    "            achieve_ratio,\n",
    "            earned_star,\n",
    "            time_per_success,\n",
    "            h_idx,\n",
    "            nmu,\n",
    "            log_jerk,\n",
    "            sp_arc,\n",
    "            finger_coordination,\n",
    "        ]\n",
    "        dic = {\"Mission ID\": self.mid}\n",
    "        for d in feature_list:\n",
    "            dic.update(d)\n",
    "\n",
    "        if result == \"df\":\n",
    "            return pd.DataFrame.from_dict(dic, orient=\"index\")\n",
    "        elif (result == \"dic\") or (result == \"dict\"):\n",
    "            return dic\n",
    "        else:\n",
    "            return dic\n",
    "\n",
    "    def get_peak_gap_feature(self, motion):\n",
    "\n",
    "        \"\"\"Calculate features for each motion (unit of motion). \n",
    "\n",
    "        Args:\n",
    "            motion: in (\"pp\", \"pm\", \"gi\", \"go\")\n",
    "            \n",
    "        Returns:\n",
    "            Pandas DataFrame consists of features of each motion. \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        df_raw, ls = self.get_df()\n",
    "        \n",
    "        df_peak = self.peak_gap_info(p_or_g=\"p\", mod=0)\n",
    "        \n",
    "        df_gap = self.peak_gap_info(p_or_g=\"g\", mod=0)\n",
    "        \n",
    "\n",
    "        # 2. Peak idx info\n",
    "\n",
    "        df_peak[\"len\"] = df_peak[\"idx\"].map(\n",
    "            lambda x: (\n",
    "                df_raw.loc[x[-1], \"timestamp\"] - df_raw.loc[x[0], \"timestamp\"]\n",
    "            ).total_seconds()\n",
    "        )\n",
    "        \n",
    "\n",
    "        # 2-1. Peak angle info\n",
    "\n",
    "        df_peak[\"angle_median\"] = df_peak[\"angle\"].map(np.median)\n",
    "        df_peak[\"angle_max\"] = df_peak[\"angle\"].map(\n",
    "            lambda x: np.percentile(x, 95) if (np.mean(x) > 0) else np.percentile(x, 5)\n",
    "        )\n",
    "        df_peak[\"angle_iqr\"] = df_peak[\"angle\"].map(stats.iqr)\n",
    "        df_peak[\"angle_kurtosis\"] = df_peak[\"angle\"].map(stats.kurtosis)\n",
    "\n",
    "        # 2-2. Peak speed info\n",
    "        df_peak[\"speed\"] = df_peak[\"speed\"].map(lambda x: reject_outliers(x, \"speed\"))\n",
    "        df_peak[\"speed_median\"] = df_peak[\"speed\"].map(np.median)\n",
    "        df_peak[\"speed_iqr\"] = df_peak[\"speed\"].map(stats.iqr)\n",
    "        df_peak[\"speed_kurtosis\"] = df_peak[\"speed\"].map(stats.kurtosis)\n",
    "        df_peak[\"speed_zero_cross\"] = df_peak[\"speed\"].map(zero_crossing)\n",
    "        \n",
    "\n",
    "        # 2-3. Peak acceleration info\n",
    "        df_peak[\"acc_zero_cross\"] = df_peak[\"acceleration\"].map(zero_crossing)\n",
    "        \n",
    "\n",
    "        # 3. Gap idx info\n",
    "        df_gap[\"len\"] = df_gap[\"idx\"].map(\n",
    "            lambda x: (\n",
    "                df_raw.loc[x[-1], \"timestamp\"] - df_raw.loc[x[0], \"timestamp\"]\n",
    "            ).total_seconds()\n",
    "        )\n",
    "        \n",
    "        # 3-1. Gap angle info\n",
    "        # Seems no need for angle info of gaps\n",
    "\n",
    "        # 3-2. gap speed info\n",
    "        df_gap[\"speed\"] = df_gap[\"speed\"].map(lambda x: reject_outliers(x, \"speed\"))\n",
    "        df_gap[\"speed_median\"] = df_gap[\"speed\"].map(np.median)\n",
    "        df_gap[\"speed_max\"] = df_gap[\"speed\"].map(\n",
    "            lambda x: np.percentile(x, 95) if (np.mean(x) > 0) else np.percentile(x, 5)\n",
    "        )\n",
    "        df_gap[\"speed_zero_cross\"] = df_gap[\"speed\"].map(zero_crossing)\n",
    "        \n",
    "        # 3-3. gap acceleration info\n",
    "        df_gap[\"acc_zero_cross\"] = df_gap[\"acceleration\"].map(zero_crossing)\n",
    "        \n",
    "        # 4. Divide dataframe by motion and return\n",
    "        df_peak[\"range\"] = df_peak[\"angle\"].map(np.mean)\n",
    "        df_gap[\"start\"] = df_gap[\"angle\"].map(lambda x: x[0])\n",
    "        \n",
    "        if motion == \"pp\":\n",
    "            df_peak_p = df_peak[df_peak[\"range\"] >= self.range[1]].drop(\n",
    "                columns=[\"range\"]\n",
    "            )\n",
    "            \n",
    "            return df_peak_p\n",
    "        elif motion == \"pm\":\n",
    "            df_peak_m = df_peak[df_peak[\"range\"] <= self.range[0]].drop(\n",
    "                columns=[\"range\"]\n",
    "            )\n",
    "            return df_peak_m\n",
    "        elif motion == \"gi\":\n",
    "            # inner: pronation, flexion, R.D. / outer: supination, extension, U.D.\n",
    "            df_gap_inner = df_gap[df_gap[\"start\"] > (sum(self.range) / 2)].drop(\n",
    "                columns=[\"start\"]\n",
    "            )\n",
    "            return df_gap_inner\n",
    "        elif motion == \"go\":\n",
    "            df_gap_outer = df_gap[df_gap[\"start\"] < (sum(self.range) / 2)].drop(\n",
    "                columns=[\"start\"]\n",
    "            )\n",
    "            return df_gap_outer\n",
    "\n",
    "    def aggregate_feature(self, motion=\"all\"):\n",
    "\n",
    "        \"\"\"Get aggregate statistics (centrality & variability) from EMR.\n",
    "        \n",
    "        Args:\n",
    "            motion: in ('all', \"pp\", \"pm\", \"gi\", \"go\"). 특정 motion에 대한 feature만 필요한 경우 입력.\n",
    "\n",
    "        Returns:\n",
    "            Pandas DataFrame. aggregate features(statistics) of EMR.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        if motion in (\"pp\", \"pm\", \"gi\", \"go\"):\n",
    "            df = self.get_peak_gap_feature(motion)\n",
    "            df_feature = df.describe().T\n",
    "            df_feature[\"normality\"] = (\n",
    "                df.iloc[:, 4:].apply(stats.shapiro, axis=0).map(lambda x: x[1] >= 0.05)\n",
    "            )\n",
    "            df_feature[\"motion\"] = motion\n",
    "        else:\n",
    "            ls = []\n",
    "\n",
    "            for name in [\"pp\", \"pm\", \"gi\", \"go\"]:\n",
    "\n",
    "                df = self.get_peak_gap_feature(name)\n",
    "\n",
    "                df_feature_each = df.describe().T\n",
    "\n",
    "                df_feature_each[\"normality\"] = (\n",
    "                    df.iloc[:, 4:]\n",
    "                    .apply(stats.shapiro, axis=0)\n",
    "                    .map(lambda x: x[1] >= 0.05)\n",
    "                )\n",
    "\n",
    "                df_feature_each[\"motion\"] = name\n",
    "\n",
    "                ls.append(df_feature_each)\n",
    "\n",
    "            df_feature = pd.concat(ls)\n",
    "\n",
    "        df_feature[\"iqr\"] = df_feature[\"75%\"] - df_feature[\"25%\"]\n",
    "\n",
    "        df_feature.rename(columns={\"50%\": \"median\"}, inplace=True)\n",
    "\n",
    "        df_feature.drop(columns=[\"25%\", \"75%\"], inplace=True)\n",
    "\n",
    "        return df_feature\n",
    "\n",
    "    def h_index(self, thres_v, thres_t):\n",
    "\n",
    "        \"\"\"number of maintaining attempts of under threshold speed with threshold time (in seconds)\n",
    "        \n",
    "        Args:\n",
    "            thres_v: threshold speed to count as maintaining motion.\n",
    "            thres_t: threshold time to count as an attempt\n",
    "\n",
    "        Returns:\n",
    "            h_idx (integer)\n",
    "        \"\"\"\n",
    "\n",
    "        df_speed = self.get_speed(sub=0, filtering=1)\n",
    "        thres_l = int(33.5 * thres_t)\n",
    "        np_speed = df_speed.to_numpy()\n",
    "        np_tf = abs(np_speed) < thres_v\n",
    "        group = [(v, sum(1 for i in n)) for v, n in groupby(np_tf)]\n",
    "        h_idx = 0\n",
    "        for (tf, count) in group:\n",
    "            if tf and count >= thres_l:\n",
    "                h_idx += 1\n",
    "            else:\n",
    "                pass\n",
    "        return h_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
